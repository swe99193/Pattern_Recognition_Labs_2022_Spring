{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16859,"status":"ok","timestamp":1655034706053,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"PP5_b_AD38WG","outputId":"28dd37b5-b2a7-4854-b31d-116b6ff503b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4h9YJylEy4-i","executionInfo":{"status":"ok","timestamp":1655034706054,"user_tz":-480,"elapsed":4,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["path1 = \"/content/drive/MyDrive/Current Workspace/Pattern Recognition/x_train.npy\"  # x_train\n","path2 = \"/content/drive/MyDrive/Current Workspace/Pattern Recognition/y_train.npy\"  # y_train\n","path3 = \"/content/drive/MyDrive/Current Workspace/Pattern Recognition/x_test.npy\"  # x_test\n","path4 = \"/content/drive/MyDrive/Current Workspace/Pattern Recognition/y_test.npy\"  # y_test"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"l0iDvBv0QOKU","executionInfo":{"status":"ok","timestamp":1655034709289,"user_tz":-480,"elapsed":3238,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from PIL import Image\n","import copy\n","from torchsummary import summary\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, models, transforms\n","import torchvision\n","from torch.optim import lr_scheduler\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655034709290,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"hPlh4cAuBiL9","outputId":"267e89db-11e1-4487-ad2b-89315d09f5c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"P3MaKsgrQOKY"},"source":["## Load data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2248,"status":"ok","timestamp":1655034711533,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"HLRBmIC6QOKY","outputId":"5d89993e-d185-4788-9b01-357aae0d5788"},"outputs":[{"output_type":"stream","name":"stdout","text":["50000 train samples\n","10000 test samples\n"]}],"source":["x_train = np.load(path1)\n","y_train = np.load(path2)\n","y_train = y_train.reshape(len(y_train))\n","\n","x_test = np.load(path3)\n","y_test = np.load(path4)\n","y_test = y_test.reshape(len(y_test))\n","\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1655034711534,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"U9j9nU7MQOKZ","outputId":"6ca1dcdf-025f-4f74-c842-a02042b5d335"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3 4 5 6 7 8 9]\n"]}],"source":["# It's a multi-class classification problem\n","class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n","               'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n","print(np.unique(y_train))"]},{"cell_type":"markdown","metadata":{"id":"sXDJ_uLAQOKZ"},"source":["![image](https://img-blog.csdnimg.cn/20190623084800880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMDEz,size_16,color_FFFFFF,t_70)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":1170,"status":"ok","timestamp":1655034712700,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"EPCcluo5KIWM","outputId":"8c1bd937-f352-4086-d5da-2b345c6e4c09"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["i = 100\n","plt.imshow(x_train[i])\n","print(y_train[i])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1655034712700,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"Zek_HwQSat1-","outputId":"adcd7fce-a5f0-45d6-c97e-8d27ab1f3c75"},"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 32, 3)\n"]}],"source":["print(x_train[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"ZwzN5UNPQOKZ"},"source":["## Data preprocess"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"i6_sVtdohLT5","executionInfo":{"status":"ok","timestamp":1655034712701,"user_tz":-480,"elapsed":15,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        # transforms.Resize((256, 256)),\n","        # transforms.RandomCrop((224, 224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        # transforms.Resize(256),\n","        # transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        # transforms.Resize(256),\n","        # transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","}\n","\n","img = Image.fromarray(x_train[100])\n","tmp = data_transforms['train'](img)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"yxbrX3Ksw0no","executionInfo":{"status":"ok","timestamp":1655034712701,"user_tz":-480,"elapsed":14,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, X, y, transform=None):\n","        self.X = X\n","        self.y = y\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        X = self.X[index]\n","\n","        if self.transform:\n","            X = self.transform(Image.fromarray(X))\n","\n","        y = self.y[index]\n","\n","        return X, y\n","\n","    def __len__(self):\n","        return self.y.shape[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"lQb_x4aZ_9wB","executionInfo":{"status":"ok","timestamp":1655034712701,"user_tz":-480,"elapsed":14,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["# split dataset\n","datasets = {}\n","train_size = 47000\n","\n","datasets['train'] = CustomDataset(\n","    x_train[:train_size], y_train[:train_size], data_transforms['train'])\n","datasets['val'] = CustomDataset(\n","    x_train[train_size:], y_train[train_size:], data_transforms['val'])\n","datasets['test'] = CustomDataset(x_test, y_test, data_transforms['test'])"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"IkmhI_m3j-Sh","executionInfo":{"status":"ok","timestamp":1655034712702,"user_tz":-480,"elapsed":14,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["# show image in datasets\n","tmp_x, tmp_y = datasets['train'][1000]\n","#print(tmp_y)\n","# plt.imshow(tmp_x.permute(1, 2, 0))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"twKPdhq3MiUq","executionInfo":{"status":"ok","timestamp":1655034712702,"user_tz":-480,"elapsed":14,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["dataloaders = {x: DataLoader(datasets[x], batch_size=512, shuffle=True)\n","               for x in ['train', 'val']}\n","dataloaders['test'] = DataLoader(\n","    datasets['test'], batch_size=2000, shuffle=False)\n","dataset_sizes = {x: len(datasets[x]) for x in ['train', 'val', 'test']}\n","class_names = ['airplane', 'automobile', 'bird', 'cat',\n","               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1655034712702,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"xk9kASvZRPDT","outputId":"903e3444-f92c-4a81-a89a-c971fd433af7"},"outputs":[{"output_type":"stream","name":"stdout","text":["47000\n","3000\n","10000\n"]}],"source":["print(dataset_sizes['train'])\n","print(dataset_sizes['val'])\n","print(dataset_sizes['test'])"]},{"cell_type":"markdown","metadata":{"id":"CUHBh-gL_3bC"},"source":["## My Model"]},{"cell_type":"markdown","metadata":{"id":"c5If2TZDSSOY"},"source":["### Pretrained Model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2nYwg0nDSGVe","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["9df1ee8d3add47bd9932dd9f60980024","19c342253ec34aee9a65e37285e6c383","73c1acd475d74b9cbce6a0f9aa4d016c","93e740f631624f5a98eda09c03309261","cbfea231975643cb8c41f69b44a870ff","5cb54787c8ca48e18808401d1125ef63","fc832b866e424e2c88d01079918b07cc","0ad79d4891bd48099c3d7c9f22d441fa","0b3d7fd57ffc40beb0300e97657bfbe8","d002e042a0cd49939b38d972f6e5d9ad","43546ebea8834cf7a03925e8a84f9ab9"]},"executionInfo":{"status":"ok","timestamp":1655034729039,"user_tz":-480,"elapsed":16345,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}},"outputId":"b4578d3b-e94e-4f9a-96d1-74398dd4e5a4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/230M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df1ee8d3add47bd9932dd9f60980024"}},"metadata":{}}],"source":["model_conv = torchvision.models.resnet152(pretrained=True)\n","# for param in model_conv.parameters():\n","#     param.requires_grad = False\n","\n","# Parameters of newly constructed modules have requires_grad=True by default\n","num_ftrs = model_conv.fc.in_features\n","model_conv.fc = nn.Linear(num_ftrs, 10)\n","\n","model_conv = model_conv.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","# Observe that only parameters of final layer are being optimized as\n","# opposed to before.\n","# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.01, momentum=0.9, weight_decay=?)\n","optimizer_conv = optim.Adam(model_conv.parameters(),\n","                            lr=0.001,\n","                            betas=(0.9, 0.999),\n","                            eps=1e-08,\n","                            weight_decay=1e-5,\n","                            amsgrad=False)\n","\n","# Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1655034729545,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"NwN8KYTVGv2M","outputId":"fc57aa94-af81-49d6-bbd8-e90c792db75a"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-80          [-1, 128, 28, 28]             256\n","             ReLU-81          [-1, 128, 28, 28]               0\n","           Conv2d-82          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-83          [-1, 128, 28, 28]             256\n","             ReLU-84          [-1, 128, 28, 28]               0\n","           Conv2d-85          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n","             ReLU-87          [-1, 512, 28, 28]               0\n","       Bottleneck-88          [-1, 512, 28, 28]               0\n","           Conv2d-89          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-90          [-1, 128, 28, 28]             256\n","             ReLU-91          [-1, 128, 28, 28]               0\n","           Conv2d-92          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-93          [-1, 128, 28, 28]             256\n","             ReLU-94          [-1, 128, 28, 28]               0\n","           Conv2d-95          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n","             ReLU-97          [-1, 512, 28, 28]               0\n","       Bottleneck-98          [-1, 512, 28, 28]               0\n","           Conv2d-99          [-1, 128, 28, 28]          65,536\n","     BatchNorm2d-100          [-1, 128, 28, 28]             256\n","            ReLU-101          [-1, 128, 28, 28]               0\n","          Conv2d-102          [-1, 128, 28, 28]         147,456\n","     BatchNorm2d-103          [-1, 128, 28, 28]             256\n","            ReLU-104          [-1, 128, 28, 28]               0\n","          Conv2d-105          [-1, 512, 28, 28]          65,536\n","     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n","            ReLU-107          [-1, 512, 28, 28]               0\n","      Bottleneck-108          [-1, 512, 28, 28]               0\n","          Conv2d-109          [-1, 128, 28, 28]          65,536\n","     BatchNorm2d-110          [-1, 128, 28, 28]             256\n","            ReLU-111          [-1, 128, 28, 28]               0\n","          Conv2d-112          [-1, 128, 28, 28]         147,456\n","     BatchNorm2d-113          [-1, 128, 28, 28]             256\n","            ReLU-114          [-1, 128, 28, 28]               0\n","          Conv2d-115          [-1, 512, 28, 28]          65,536\n","     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n","            ReLU-117          [-1, 512, 28, 28]               0\n","      Bottleneck-118          [-1, 512, 28, 28]               0\n","          Conv2d-119          [-1, 256, 28, 28]         131,072\n","     BatchNorm2d-120          [-1, 256, 28, 28]             512\n","            ReLU-121          [-1, 256, 28, 28]               0\n","          Conv2d-122          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-123          [-1, 256, 14, 14]             512\n","            ReLU-124          [-1, 256, 14, 14]               0\n","          Conv2d-125         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n","          Conv2d-127         [-1, 1024, 14, 14]         524,288\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-142          [-1, 256, 14, 14]             512\n","            ReLU-143          [-1, 256, 14, 14]               0\n","          Conv2d-144          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-145          [-1, 256, 14, 14]             512\n","            ReLU-146          [-1, 256, 14, 14]               0\n","          Conv2d-147         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n","            ReLU-149         [-1, 1024, 14, 14]               0\n","      Bottleneck-150         [-1, 1024, 14, 14]               0\n","          Conv2d-151          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-152          [-1, 256, 14, 14]             512\n","            ReLU-153          [-1, 256, 14, 14]               0\n","          Conv2d-154          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-155          [-1, 256, 14, 14]             512\n","            ReLU-156          [-1, 256, 14, 14]               0\n","          Conv2d-157         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n","            ReLU-159         [-1, 1024, 14, 14]               0\n","      Bottleneck-160         [-1, 1024, 14, 14]               0\n","          Conv2d-161          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-162          [-1, 256, 14, 14]             512\n","            ReLU-163          [-1, 256, 14, 14]               0\n","          Conv2d-164          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-165          [-1, 256, 14, 14]             512\n","            ReLU-166          [-1, 256, 14, 14]               0\n","          Conv2d-167         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n","            ReLU-169         [-1, 1024, 14, 14]               0\n","      Bottleneck-170         [-1, 1024, 14, 14]               0\n","          Conv2d-171          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-172          [-1, 256, 14, 14]             512\n","            ReLU-173          [-1, 256, 14, 14]               0\n","          Conv2d-174          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-175          [-1, 256, 14, 14]             512\n","            ReLU-176          [-1, 256, 14, 14]               0\n","          Conv2d-177         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n","            ReLU-179         [-1, 1024, 14, 14]               0\n","      Bottleneck-180         [-1, 1024, 14, 14]               0\n","          Conv2d-181          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-182          [-1, 256, 14, 14]             512\n","            ReLU-183          [-1, 256, 14, 14]               0\n","          Conv2d-184          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-185          [-1, 256, 14, 14]             512\n","            ReLU-186          [-1, 256, 14, 14]               0\n","          Conv2d-187         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n","            ReLU-189         [-1, 1024, 14, 14]               0\n","      Bottleneck-190         [-1, 1024, 14, 14]               0\n","          Conv2d-191          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-192          [-1, 256, 14, 14]             512\n","            ReLU-193          [-1, 256, 14, 14]               0\n","          Conv2d-194          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-195          [-1, 256, 14, 14]             512\n","            ReLU-196          [-1, 256, 14, 14]               0\n","          Conv2d-197         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n","            ReLU-199         [-1, 1024, 14, 14]               0\n","      Bottleneck-200         [-1, 1024, 14, 14]               0\n","          Conv2d-201          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-202          [-1, 256, 14, 14]             512\n","            ReLU-203          [-1, 256, 14, 14]               0\n","          Conv2d-204          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-205          [-1, 256, 14, 14]             512\n","            ReLU-206          [-1, 256, 14, 14]               0\n","          Conv2d-207         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n","            ReLU-209         [-1, 1024, 14, 14]               0\n","      Bottleneck-210         [-1, 1024, 14, 14]               0\n","          Conv2d-211          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-212          [-1, 256, 14, 14]             512\n","            ReLU-213          [-1, 256, 14, 14]               0\n","          Conv2d-214          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-215          [-1, 256, 14, 14]             512\n","            ReLU-216          [-1, 256, 14, 14]               0\n","          Conv2d-217         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n","            ReLU-219         [-1, 1024, 14, 14]               0\n","      Bottleneck-220         [-1, 1024, 14, 14]               0\n","          Conv2d-221          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-222          [-1, 256, 14, 14]             512\n","            ReLU-223          [-1, 256, 14, 14]               0\n","          Conv2d-224          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-225          [-1, 256, 14, 14]             512\n","            ReLU-226          [-1, 256, 14, 14]               0\n","          Conv2d-227         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n","            ReLU-229         [-1, 1024, 14, 14]               0\n","      Bottleneck-230         [-1, 1024, 14, 14]               0\n","          Conv2d-231          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-232          [-1, 256, 14, 14]             512\n","            ReLU-233          [-1, 256, 14, 14]               0\n","          Conv2d-234          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-235          [-1, 256, 14, 14]             512\n","            ReLU-236          [-1, 256, 14, 14]               0\n","          Conv2d-237         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n","            ReLU-239         [-1, 1024, 14, 14]               0\n","      Bottleneck-240         [-1, 1024, 14, 14]               0\n","          Conv2d-241          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-242          [-1, 256, 14, 14]             512\n","            ReLU-243          [-1, 256, 14, 14]               0\n","          Conv2d-244          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-245          [-1, 256, 14, 14]             512\n","            ReLU-246          [-1, 256, 14, 14]               0\n","          Conv2d-247         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n","            ReLU-249         [-1, 1024, 14, 14]               0\n","      Bottleneck-250         [-1, 1024, 14, 14]               0\n","          Conv2d-251          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-252          [-1, 256, 14, 14]             512\n","            ReLU-253          [-1, 256, 14, 14]               0\n","          Conv2d-254          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-255          [-1, 256, 14, 14]             512\n","            ReLU-256          [-1, 256, 14, 14]               0\n","          Conv2d-257         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n","            ReLU-259         [-1, 1024, 14, 14]               0\n","      Bottleneck-260         [-1, 1024, 14, 14]               0\n","          Conv2d-261          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-262          [-1, 256, 14, 14]             512\n","            ReLU-263          [-1, 256, 14, 14]               0\n","          Conv2d-264          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-265          [-1, 256, 14, 14]             512\n","            ReLU-266          [-1, 256, 14, 14]               0\n","          Conv2d-267         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n","            ReLU-269         [-1, 1024, 14, 14]               0\n","      Bottleneck-270         [-1, 1024, 14, 14]               0\n","          Conv2d-271          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-272          [-1, 256, 14, 14]             512\n","            ReLU-273          [-1, 256, 14, 14]               0\n","          Conv2d-274          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-275          [-1, 256, 14, 14]             512\n","            ReLU-276          [-1, 256, 14, 14]               0\n","          Conv2d-277         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n","            ReLU-279         [-1, 1024, 14, 14]               0\n","      Bottleneck-280         [-1, 1024, 14, 14]               0\n","          Conv2d-281          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-282          [-1, 256, 14, 14]             512\n","            ReLU-283          [-1, 256, 14, 14]               0\n","          Conv2d-284          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-285          [-1, 256, 14, 14]             512\n","            ReLU-286          [-1, 256, 14, 14]               0\n","          Conv2d-287         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n","            ReLU-289         [-1, 1024, 14, 14]               0\n","      Bottleneck-290         [-1, 1024, 14, 14]               0\n","          Conv2d-291          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-292          [-1, 256, 14, 14]             512\n","            ReLU-293          [-1, 256, 14, 14]               0\n","          Conv2d-294          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-295          [-1, 256, 14, 14]             512\n","            ReLU-296          [-1, 256, 14, 14]               0\n","          Conv2d-297         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n","            ReLU-299         [-1, 1024, 14, 14]               0\n","      Bottleneck-300         [-1, 1024, 14, 14]               0\n","          Conv2d-301          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-302          [-1, 256, 14, 14]             512\n","            ReLU-303          [-1, 256, 14, 14]               0\n","          Conv2d-304          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-305          [-1, 256, 14, 14]             512\n","            ReLU-306          [-1, 256, 14, 14]               0\n","          Conv2d-307         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n","            ReLU-309         [-1, 1024, 14, 14]               0\n","      Bottleneck-310         [-1, 1024, 14, 14]               0\n","          Conv2d-311          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-312          [-1, 256, 14, 14]             512\n","            ReLU-313          [-1, 256, 14, 14]               0\n","          Conv2d-314          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-315          [-1, 256, 14, 14]             512\n","            ReLU-316          [-1, 256, 14, 14]               0\n","          Conv2d-317         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n","            ReLU-319         [-1, 1024, 14, 14]               0\n","      Bottleneck-320         [-1, 1024, 14, 14]               0\n","          Conv2d-321          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-322          [-1, 256, 14, 14]             512\n","            ReLU-323          [-1, 256, 14, 14]               0\n","          Conv2d-324          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-325          [-1, 256, 14, 14]             512\n","            ReLU-326          [-1, 256, 14, 14]               0\n","          Conv2d-327         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n","            ReLU-329         [-1, 1024, 14, 14]               0\n","      Bottleneck-330         [-1, 1024, 14, 14]               0\n","          Conv2d-331          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-332          [-1, 256, 14, 14]             512\n","            ReLU-333          [-1, 256, 14, 14]               0\n","          Conv2d-334          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-335          [-1, 256, 14, 14]             512\n","            ReLU-336          [-1, 256, 14, 14]               0\n","          Conv2d-337         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n","            ReLU-339         [-1, 1024, 14, 14]               0\n","      Bottleneck-340         [-1, 1024, 14, 14]               0\n","          Conv2d-341          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-342          [-1, 256, 14, 14]             512\n","            ReLU-343          [-1, 256, 14, 14]               0\n","          Conv2d-344          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-345          [-1, 256, 14, 14]             512\n","            ReLU-346          [-1, 256, 14, 14]               0\n","          Conv2d-347         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n","            ReLU-349         [-1, 1024, 14, 14]               0\n","      Bottleneck-350         [-1, 1024, 14, 14]               0\n","          Conv2d-351          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-352          [-1, 256, 14, 14]             512\n","            ReLU-353          [-1, 256, 14, 14]               0\n","          Conv2d-354          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-355          [-1, 256, 14, 14]             512\n","            ReLU-356          [-1, 256, 14, 14]               0\n","          Conv2d-357         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n","            ReLU-359         [-1, 1024, 14, 14]               0\n","      Bottleneck-360         [-1, 1024, 14, 14]               0\n","          Conv2d-361          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-362          [-1, 256, 14, 14]             512\n","            ReLU-363          [-1, 256, 14, 14]               0\n","          Conv2d-364          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-365          [-1, 256, 14, 14]             512\n","            ReLU-366          [-1, 256, 14, 14]               0\n","          Conv2d-367         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n","            ReLU-369         [-1, 1024, 14, 14]               0\n","      Bottleneck-370         [-1, 1024, 14, 14]               0\n","          Conv2d-371          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-372          [-1, 256, 14, 14]             512\n","            ReLU-373          [-1, 256, 14, 14]               0\n","          Conv2d-374          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-375          [-1, 256, 14, 14]             512\n","            ReLU-376          [-1, 256, 14, 14]               0\n","          Conv2d-377         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n","            ReLU-379         [-1, 1024, 14, 14]               0\n","      Bottleneck-380         [-1, 1024, 14, 14]               0\n","          Conv2d-381          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-382          [-1, 256, 14, 14]             512\n","            ReLU-383          [-1, 256, 14, 14]               0\n","          Conv2d-384          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-385          [-1, 256, 14, 14]             512\n","            ReLU-386          [-1, 256, 14, 14]               0\n","          Conv2d-387         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n","            ReLU-389         [-1, 1024, 14, 14]               0\n","      Bottleneck-390         [-1, 1024, 14, 14]               0\n","          Conv2d-391          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-392          [-1, 256, 14, 14]             512\n","            ReLU-393          [-1, 256, 14, 14]               0\n","          Conv2d-394          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-395          [-1, 256, 14, 14]             512\n","            ReLU-396          [-1, 256, 14, 14]               0\n","          Conv2d-397         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n","            ReLU-399         [-1, 1024, 14, 14]               0\n","      Bottleneck-400         [-1, 1024, 14, 14]               0\n","          Conv2d-401          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-402          [-1, 256, 14, 14]             512\n","            ReLU-403          [-1, 256, 14, 14]               0\n","          Conv2d-404          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-405          [-1, 256, 14, 14]             512\n","            ReLU-406          [-1, 256, 14, 14]               0\n","          Conv2d-407         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n","            ReLU-409         [-1, 1024, 14, 14]               0\n","      Bottleneck-410         [-1, 1024, 14, 14]               0\n","          Conv2d-411          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-412          [-1, 256, 14, 14]             512\n","            ReLU-413          [-1, 256, 14, 14]               0\n","          Conv2d-414          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-415          [-1, 256, 14, 14]             512\n","            ReLU-416          [-1, 256, 14, 14]               0\n","          Conv2d-417         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n","            ReLU-419         [-1, 1024, 14, 14]               0\n","      Bottleneck-420         [-1, 1024, 14, 14]               0\n","          Conv2d-421          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-422          [-1, 256, 14, 14]             512\n","            ReLU-423          [-1, 256, 14, 14]               0\n","          Conv2d-424          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-425          [-1, 256, 14, 14]             512\n","            ReLU-426          [-1, 256, 14, 14]               0\n","          Conv2d-427         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n","            ReLU-429         [-1, 1024, 14, 14]               0\n","      Bottleneck-430         [-1, 1024, 14, 14]               0\n","          Conv2d-431          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-432          [-1, 256, 14, 14]             512\n","            ReLU-433          [-1, 256, 14, 14]               0\n","          Conv2d-434          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-435          [-1, 256, 14, 14]             512\n","            ReLU-436          [-1, 256, 14, 14]               0\n","          Conv2d-437         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n","            ReLU-439         [-1, 1024, 14, 14]               0\n","      Bottleneck-440         [-1, 1024, 14, 14]               0\n","          Conv2d-441          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-442          [-1, 256, 14, 14]             512\n","            ReLU-443          [-1, 256, 14, 14]               0\n","          Conv2d-444          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-445          [-1, 256, 14, 14]             512\n","            ReLU-446          [-1, 256, 14, 14]               0\n","          Conv2d-447         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n","            ReLU-449         [-1, 1024, 14, 14]               0\n","      Bottleneck-450         [-1, 1024, 14, 14]               0\n","          Conv2d-451          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-452          [-1, 256, 14, 14]             512\n","            ReLU-453          [-1, 256, 14, 14]               0\n","          Conv2d-454          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-455          [-1, 256, 14, 14]             512\n","            ReLU-456          [-1, 256, 14, 14]               0\n","          Conv2d-457         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n","            ReLU-459         [-1, 1024, 14, 14]               0\n","      Bottleneck-460         [-1, 1024, 14, 14]               0\n","          Conv2d-461          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-462          [-1, 256, 14, 14]             512\n","            ReLU-463          [-1, 256, 14, 14]               0\n","          Conv2d-464          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-465          [-1, 256, 14, 14]             512\n","            ReLU-466          [-1, 256, 14, 14]               0\n","          Conv2d-467         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n","            ReLU-469         [-1, 1024, 14, 14]               0\n","      Bottleneck-470         [-1, 1024, 14, 14]               0\n","          Conv2d-471          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-472          [-1, 256, 14, 14]             512\n","            ReLU-473          [-1, 256, 14, 14]               0\n","          Conv2d-474          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-475          [-1, 256, 14, 14]             512\n","            ReLU-476          [-1, 256, 14, 14]               0\n","          Conv2d-477         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n","            ReLU-479         [-1, 1024, 14, 14]               0\n","      Bottleneck-480         [-1, 1024, 14, 14]               0\n","          Conv2d-481          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n","            ReLU-483          [-1, 512, 14, 14]               0\n","          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n","            ReLU-486            [-1, 512, 7, 7]               0\n","          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n","          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n","            ReLU-491           [-1, 2048, 7, 7]               0\n","      Bottleneck-492           [-1, 2048, 7, 7]               0\n","          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n","            ReLU-495            [-1, 512, 7, 7]               0\n","          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n","            ReLU-498            [-1, 512, 7, 7]               0\n","          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n","            ReLU-501           [-1, 2048, 7, 7]               0\n","      Bottleneck-502           [-1, 2048, 7, 7]               0\n","          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n","            ReLU-505            [-1, 512, 7, 7]               0\n","          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n","            ReLU-508            [-1, 512, 7, 7]               0\n","          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n","            ReLU-511           [-1, 2048, 7, 7]               0\n","      Bottleneck-512           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n","          Linear-514                   [-1, 10]          20,490\n","================================================================\n","Total params: 58,164,298\n","Trainable params: 58,164,298\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 606.58\n","Params size (MB): 221.88\n","Estimated Total Size (MB): 829.04\n","----------------------------------------------------------------\n"]}],"source":["summary(model_conv, (3, 224, 224))"]},{"cell_type":"markdown","metadata":{"id":"6_uoCfPbBBum"},"source":["### train model"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"-rxzTkHuSszO","executionInfo":{"status":"ok","timestamp":1655034729903,"user_tz":-480,"elapsed":369,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["def train(model, criterion, optimizer, scheduler, num_epochs=25):\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","        # if epoch > 1:\n","        #     for param in model.parameters():\n","        #         param.requires_grad = True\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for i, data in enumerate(dataloaders[phase]):\n","                inputs, labels = data\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # for param in model_conv.parameters():\n","                    #     print(param.requires_grad)\n","\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                del inputs\n","                del labels\n","                torch.cuda.empty_cache()\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    print(f'Best val Acc: {best_acc:4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"-m8OLsLqSZVH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655035814915,"user_tz":-480,"elapsed":1085018,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}},"outputId":"dcd7b07b-9556-449c-e429-717b65f34087"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/19\n","----------\n","train Loss: 0.8242 Acc: 0.7169\n","val Loss: 0.6182 Acc: 0.7807\n","\n","Epoch 1/19\n","----------\n","train Loss: 0.4811 Acc: 0.8347\n","val Loss: 0.5730 Acc: 0.8030\n","\n","Epoch 2/19\n","----------\n","train Loss: 0.3885 Acc: 0.8670\n","val Loss: 1.3412 Acc: 0.7450\n","\n","Epoch 3/19\n","----------\n","train Loss: 0.4403 Acc: 0.8531\n","val Loss: 0.5578 Acc: 0.8153\n","\n","Epoch 4/19\n","----------\n","train Loss: 0.2922 Acc: 0.9012\n","val Loss: 0.6769 Acc: 0.8267\n","\n","Epoch 5/19\n","----------\n","train Loss: 0.2330 Acc: 0.9219\n","val Loss: 0.5894 Acc: 0.8270\n","\n","Epoch 6/19\n","----------\n","train Loss: 0.1955 Acc: 0.9348\n","val Loss: 0.5921 Acc: 0.8167\n","\n","Epoch 7/19\n","----------\n","train Loss: 0.1100 Acc: 0.9647\n","val Loss: 0.4837 Acc: 0.8557\n","\n","Epoch 8/19\n","----------\n","train Loss: 0.0642 Acc: 0.9814\n","val Loss: 0.5018 Acc: 0.8570\n","\n","Epoch 9/19\n","----------\n","train Loss: 0.0434 Acc: 0.9887\n","val Loss: 0.5445 Acc: 0.8590\n","\n","Epoch 10/19\n","----------\n","train Loss: 0.0310 Acc: 0.9922\n","val Loss: 0.5366 Acc: 0.8627\n","\n","Epoch 11/19\n","----------\n","train Loss: 0.0222 Acc: 0.9950\n","val Loss: 0.5830 Acc: 0.8573\n","\n","Epoch 12/19\n","----------\n","train Loss: 0.0152 Acc: 0.9966\n","val Loss: 0.6429 Acc: 0.8577\n","\n","Epoch 13/19\n","----------\n","train Loss: 0.0105 Acc: 0.9977\n","val Loss: 0.6727 Acc: 0.8560\n","\n","Epoch 14/19\n","----------\n","train Loss: 0.0070 Acc: 0.9984\n","val Loss: 0.6827 Acc: 0.8577\n","\n","Epoch 15/19\n","----------\n","train Loss: 0.0055 Acc: 0.9991\n","val Loss: 0.7020 Acc: 0.8587\n","\n","Epoch 16/19\n","----------\n","train Loss: 0.0051 Acc: 0.9991\n","val Loss: 0.7148 Acc: 0.8587\n","\n","Epoch 17/19\n","----------\n","train Loss: 0.0045 Acc: 0.9991\n","val Loss: 0.7305 Acc: 0.8583\n","\n","Epoch 18/19\n","----------\n","train Loss: 0.0040 Acc: 0.9993\n","val Loss: 0.7398 Acc: 0.8577\n","\n","Epoch 19/19\n","----------\n","train Loss: 0.0035 Acc: 0.9994\n","val Loss: 0.7534 Acc: 0.8590\n","\n","Best val Acc: 0.862667\n"]}],"source":["# train model\n","model_conv = train(model_conv, criterion, optimizer_conv,\n","                   exp_lr_scheduler, num_epochs=20)"]},{"cell_type":"markdown","metadata":{"id":"i_V9cDovBGPv"},"source":["### evaluate model"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"yjILEShO13pU","executionInfo":{"status":"ok","timestamp":1655035814916,"user_tz":-480,"elapsed":10,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["def predict(model):\n","    model.eval()\n","    y_pred = []\n","\n","    with torch.no_grad():\n","        for i, (inputs, labels) in enumerate(dataloaders['test']):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            del inputs\n","            del labels\n","            torch.cuda.empty_cache()\n","\n","            y_pred.extend(preds.tolist())\n","    return np.array(y_pred)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4825,"status":"ok","timestamp":1655035819737,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"},"user_tz":-480},"id":"qy4aoBvpIT4H","outputId":"e791c3d3-2377-4970-b70d-21c20c2860d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Acc:  0.8739\n"]}],"source":["# Test score\n","y_pred = predict(model_conv)\n","print(\"Test Acc: \", accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"5FuJcaSnI-kW","executionInfo":{"status":"ok","timestamp":1655035819738,"user_tz":-480,"elapsed":66,"user":{"displayName":"蕭望緯","userId":"03469415685232461012"}}},"outputs":[],"source":["# PATH = \"/content/drive/MyDrive/Current Workspace/Pattern Recognition/resnet152_wt.pth\"\n","# torch.save(model_conv.state_dict(), PATH)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"0811521_HW5.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9df1ee8d3add47bd9932dd9f60980024":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19c342253ec34aee9a65e37285e6c383","IPY_MODEL_73c1acd475d74b9cbce6a0f9aa4d016c","IPY_MODEL_93e740f631624f5a98eda09c03309261"],"layout":"IPY_MODEL_cbfea231975643cb8c41f69b44a870ff"}},"19c342253ec34aee9a65e37285e6c383":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb54787c8ca48e18808401d1125ef63","placeholder":"​","style":"IPY_MODEL_fc832b866e424e2c88d01079918b07cc","value":"100%"}},"73c1acd475d74b9cbce6a0f9aa4d016c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad79d4891bd48099c3d7c9f22d441fa","max":241627721,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b3d7fd57ffc40beb0300e97657bfbe8","value":241627721}},"93e740f631624f5a98eda09c03309261":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d002e042a0cd49939b38d972f6e5d9ad","placeholder":"​","style":"IPY_MODEL_43546ebea8834cf7a03925e8a84f9ab9","value":" 230M/230M [00:03&lt;00:00, 79.1MB/s]"}},"cbfea231975643cb8c41f69b44a870ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb54787c8ca48e18808401d1125ef63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc832b866e424e2c88d01079918b07cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ad79d4891bd48099c3d7c9f22d441fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b3d7fd57ffc40beb0300e97657bfbe8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d002e042a0cd49939b38d972f6e5d9ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43546ebea8834cf7a03925e8a84f9ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}